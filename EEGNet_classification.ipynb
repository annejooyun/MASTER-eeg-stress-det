{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from load_data import load_data\n",
    "from utils.metrics import compute_metrics\n",
    "\n",
    "from classifiers import EEGNet_classification, EEGNet_TSGL_classification, EEGNet_DeepConvNet_classification, EEGNet_ShallowConvNet_classification\n",
    "import utils.variables as v\n",
    "\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Generating all recordings ----\n",
      "All records generated\n",
      "\n",
      "---- Filtering out invalid recordings ----\n",
      "ERROR 1) Failed to read data for recording P006_S002_001\n",
      "ERROR 1) Failed to read data for recording P006_S002_002\n",
      "ERROR 1) Failed to read data for recording P028_S001_001\n",
      "ERROR 1) Failed to read data for recording P028_S001_002\n",
      "\n",
      "---- Returning valid recordings ----\n",
      "    S001_001  S001_002  S002_001  S002_002\n",
      "0        2.0       4.0       2.0       3.0\n",
      "1        3.0       6.0       2.0       5.0\n",
      "2        7.0       9.0       2.0       4.0\n",
      "3        6.0       8.0       2.0       3.0\n",
      "4        3.0       4.0       6.0       6.0\n",
      "5        6.0       8.0       NaN       NaN\n",
      "6        7.0       9.0       4.0       6.0\n",
      "7        4.0       6.0       2.0       3.0\n",
      "8        6.0       6.0       3.0       4.0\n",
      "9        1.0       2.0       1.0       1.0\n",
      "10       5.0       6.0       3.0       5.0\n",
      "11       2.0       5.0       2.0       6.0\n",
      "12       4.0       6.0       2.0       4.0\n",
      "13       4.0       8.0       1.0       3.0\n",
      "14       8.0       6.0       2.0       4.0\n",
      "15       4.0       5.0       1.0       2.0\n",
      "16       4.0       6.0       2.0       4.0\n",
      "17       4.0       7.0       3.0       5.0\n",
      "18       3.0       7.0       1.0       4.0\n",
      "19       4.0       5.0       2.0       3.0\n",
      "20       4.0       6.0       2.0       6.0\n",
      "21       5.0       6.0       2.0       4.0\n",
      "22       6.0       8.0       1.0       6.0\n",
      "23       7.0       5.0       4.0       5.0\n",
      "24       6.0       8.0       4.0       6.0\n",
      "25       3.0       6.0       3.0       4.0\n",
      "26       4.0       6.0       3.0       3.0\n",
      "27       NaN       NaN       1.0       4.0\n",
      "P006_S002_001 has invalid record length\n",
      "P006_S002_002 has invalid record length\n",
      "P010_S001_001 has invalid record length\n",
      "P013_S001_001 has invalid record length\n",
      "P013_S001_002 has invalid record length\n",
      "P020_S001_001 has invalid record length\n",
      "P023_S002_002 has invalid record length\n",
      "\n",
      "---- Labels ----\n",
      "{'P001_S001_001': 0, 'P001_S001_002': 1, 'P001_S002_001': 0, 'P001_S002_002': 0, 'P002_S001_001': 0, 'P002_S001_002': 1, 'P002_S002_001': 0, 'P002_S002_002': 1, 'P003_S001_001': 2, 'P003_S001_002': 2, 'P003_S002_001': 0, 'P003_S002_002': 1, 'P004_S001_001': 1, 'P004_S001_002': 2, 'P004_S002_001': 0, 'P004_S002_002': 0, 'P005_S001_001': 0, 'P005_S001_002': 1, 'P005_S002_001': 1, 'P005_S002_002': 1, 'P006_S001_001': 1, 'P006_S001_002': 2, 'P007_S001_001': 2, 'P007_S001_002': 2, 'P007_S002_001': 1, 'P007_S002_002': 1, 'P008_S001_001': 1, 'P008_S001_002': 1, 'P008_S002_001': 0, 'P008_S002_002': 0, 'P009_S001_001': 1, 'P009_S001_002': 1, 'P009_S002_001': 0, 'P009_S002_002': 1, 'P010_S001_002': 0, 'P010_S002_001': 0, 'P010_S002_002': 0, 'P011_S001_001': 1, 'P011_S001_002': 1, 'P011_S002_001': 0, 'P011_S002_002': 1, 'P012_S001_001': 0, 'P012_S001_002': 1, 'P012_S002_001': 0, 'P012_S002_002': 1, 'P013_S002_001': 0, 'P013_S002_002': 1, 'P014_S001_001': 1, 'P014_S001_002': 2, 'P014_S002_001': 0, 'P014_S002_002': 0, 'P015_S001_001': 2, 'P015_S001_002': 1, 'P015_S002_001': 0, 'P015_S002_002': 1, 'P016_S001_001': 1, 'P016_S001_002': 1, 'P016_S002_001': 0, 'P016_S002_002': 0, 'P017_S001_001': 1, 'P017_S001_002': 1, 'P017_S002_001': 0, 'P017_S002_002': 1, 'P018_S001_001': 1, 'P018_S001_002': 2, 'P018_S002_001': 0, 'P018_S002_002': 1, 'P019_S001_001': 0, 'P019_S001_002': 2, 'P019_S002_001': 0, 'P019_S002_002': 1, 'P020_S001_002': 1, 'P020_S002_001': 0, 'P020_S002_002': 0, 'P021_S001_001': 1, 'P021_S001_002': 1, 'P021_S002_001': 0, 'P021_S002_002': 1, 'P022_S001_001': 1, 'P022_S001_002': 1, 'P022_S002_001': 0, 'P022_S002_002': 1, 'P023_S001_001': 1, 'P023_S001_002': 2, 'P023_S002_001': 0, 'P024_S001_001': 2, 'P024_S001_002': 1, 'P024_S002_001': 1, 'P024_S002_002': 1, 'P025_S001_001': 1, 'P025_S001_002': 2, 'P025_S002_001': 1, 'P025_S002_002': 1, 'P026_S001_001': 0, 'P026_S001_002': 1, 'P026_S002_001': 0, 'P026_S002_002': 1, 'P027_S001_001': 1, 'P027_S001_002': 1, 'P027_S002_001': 0, 'P027_S002_002': 0}\n",
      "\n",
      "Length of data after removing invalid labels: 103\n",
      "Length og labels after removing invalid labels: 101\n",
      "\n",
      "The extracted keys : \n",
      "[]\n",
      "\n",
      "Length of data after removing mildly stressed subjects: 103\n",
      "Length og labels after removing  mildly stressed subjects: 101\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [28, 27]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_440\\3696312808.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pss'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\annej\\OneDrive\\Documents\\GitHub\\MASTER-eeg-stress-det\\load_data.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(data_type, label_type, epoched, binary)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Splits dataset into train, test, validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mtrain_data_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nLength of train data set: {len(train_data_dict)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Length of validation data set: {len(val_data_dict)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\OneDrive\\Documents\\GitHub\\MASTER-eeg-stress-det\\utils\\data.py\u001b[0m in \u001b[0;36msplit_dataset\u001b[1;34m(x_dict, y_dict)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m#Dividing subjects between the three datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0msubjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjects_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_labels_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[0msubjects_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjects_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2443\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2445\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2447\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [28, 27]"
     ]
    }
   ],
   "source": [
    "data_type = 'ica'\n",
    "label_type = 'pss'\n",
    "\n",
    "train_data, test_data, val_data, train_labels, test_labels, val_labels = load_data(data_type, label_type, epoched = True, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_EEGNet = EEGNet_classification(train_data, test_data, val_data, train_labels, test_labels, val_labels, data_type, epoched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_EEGNet = probs_EEGNet.argmax(axis = -1)  \n",
    "print(preds_EEGNet)\n",
    "print(test_labels[:,0].T)\n",
    "\n",
    "performance_EEGNet = compute_metrics(test_labels, preds_EEGNet)\n",
    "print(performance_EEGNet)\n",
    "\n",
    "plot_confusion_matrix(preds_EEGNet, test_labels, ['Non-Stressed', 'Stressed'], title = 'Confusion matrix for EEGNet on ICA data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_TSGL = EEGNet_TSGL_classification(train_data, test_data, val_data, train_labels, test_labels, val_labels, data_type, epoched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs_TSGL)\n",
    "preds_TSGL = probs_TSGL.argmax(axis = -1)  \n",
    "print(preds_TSGL)\n",
    "print(test_labels[:,0].T)\n",
    "\n",
    "performance_TSGL = compute_metrics(test_labels, preds_TSGL)\n",
    "print(performance_TSGL)\n",
    "\n",
    "plot_confusion_matrix(preds_TSGL, test_labels, ['Non-Stressed', 'Stressed'], title = 'Confusion matrix for TSGL on ICA data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_Deep = EEGNet_DeepConvNet_classification(train_data, test_data, val_data, train_labels, test_labels, val_labels, data_type, epoched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs_Deep)\n",
    "preds_Deep = probs_Deep.argmax(axis = -1)  \n",
    "print(preds_Deep)\n",
    "print(test_labels.T)\n",
    "\n",
    "performance_Deep = compute_metrics(test_labels, preds_Deep)\n",
    "print(performance_Deep)\n",
    "plot_confusion_matrix(preds_Deep, test_labels, ['Non-Stressed', 'Stressed'], title = 'Confusion matrix for DeepConvNet on New_ICA data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_Shallow = EEGNet_ShallowConvNet_classification(train_data, test_data, val_data, train_labels, test_labels, val_labels, data_type, epoched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs_Shallow)\n",
    "preds_Shallow = probs_Shallow.argmax(axis = -1)  \n",
    "print(preds_Shallow)\n",
    "print(test_labels.T)\n",
    "\n",
    "performance_Shallow = compute_metrics(test_labels, preds_Shallow)\n",
    "print(performance_Shallow)\n",
    "\n",
    "plot_confusion_matrix(preds_Shallow, test_labels, ['Non-Stressed', 'Stressed'], title = 'Confusion matrix for ShallowConvNet on ICA data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6df28382c6e70c1c1d3c02fa7b17b6f3b6fcf9f5d22d2410beebd122bfaf45e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
