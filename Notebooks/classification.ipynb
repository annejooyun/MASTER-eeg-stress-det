{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(1, module_path + '/utils/')\n",
    "import valid_recs as vrecs\n",
    "import data\n",
    "import labels\n",
    "import features\n",
    "import classifiers as cls\n",
    "import variables as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_recs = vrecs.get_valid_recs(data_type='ica', output_type = 'mne')\n",
    "\n",
    "x_dict = data.extract_eeg_data(valid_recs, data_type='ica', output_type='mne')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = labels.get_stai_labels(valid_recs) \n",
    "#y_dict =labels.get_pss_labels(valid_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_dict))\n",
    "print(len(y_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_val = 1\n",
    "rem=[]\n",
    "for i in y_dict.keys():\n",
    "    if y_dict[i] is targ_val:\n",
    "        rem.append(i)\n",
    "# printing result\n",
    "print(\"\\nThe extracted keys : \\n\" + str(rem))\n",
    "\n",
    "[y_dict.pop(key) for key in rem]\n",
    "[x_dict.pop(key) for key in rem]\n",
    "print(f\"\\nDictionary after removal of keys from y_dict: \\n {y_dict.keys()}\")\n",
    "print(f\"\\nDictionary after removal of keys from x_dict: \\n {x_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_epochs, y_epochs = data.segment_data(x_dict, y_dict, epoch_duration=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_epochs)\n",
    "\n",
    "#x_epochs_df = pd.DataFrame.from_dict(x_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.kfold_split(x_epochs, y_epochs, n_splits=2, shuffle=True, random_state=42)\n",
    "train_epochs, test_epochs, train_labels, test_labels = splits\n",
    "y_train = [np.array([v for _, v in train_labels[i].items()]) for i in range(len(train_labels))]\n",
    "y_test = [np.array([v for _, v in test_labels[i].items()]) for i in range(len(test_labels))]\n",
    "\n",
    "\n",
    "#x, x_test, y, test_labels = train_test_split(x_epochs, y_epochs, test_size=0.2, random_state=1)\n",
    "#x_train, x_val, train_labels, val_labels = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "# freq_bands = np.array([1, 4, 8, 12, 30, 50])\n",
    "# features = freq_band_features(dataset, freq_bands)\n",
    "# features = hjorth_features(dataset)\n",
    "# features = entropy_features(dataset)\n",
    "#  features = fractal_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = features.time_series_features(train_epochs) \n",
    "x_test = features.time_series_features(test_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0].shape)\n",
    "\n",
    "print(len(train_epochs[0]))\n",
    "print(train_epochs[0]['P001_S001_001_epoch0'].shape)\n",
    "print(train_epochs[0]['P001_S001_001_epoch0'][7].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the scattering transform of a speech recording\n",
    "======================================================\n",
    "This script loads a speech signal consisting of an excerpt from a recording of\n",
    "*Sense and Sensibility*. We then compute its scattering transform, and display\n",
    "the zeroth-, first-, and second-order scattering coefficients.\n",
    "\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "# Preliminaries\n",
    "# -------------\n",
    "#\n",
    "###############################################################################\n",
    "# To manipulate the audio signal, we first import NumPy. We also import\n",
    "# `librosa`, which allows us to automatically download the example signal.\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "###############################################################################\n",
    "# We import `matplotlib` to plot the calculated scattering coefficients.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we import the `Scattering1D` class from the `scattering` package.\n",
    "# The `Scattering1D` class is what lets us calculate the scattering transform\n",
    "\n",
    "from kymatio.numpy import Scattering1D\n",
    "\n",
    "###############################################################################\n",
    "# Scattering setup\n",
    "# ----------------\n",
    "# First, we download the signal and extract the second second of it (the first\n",
    "# second is mostly silence).\n",
    "\n",
    "#x, sr = librosa.load(librosa.example(\"libri3\"))\n",
    "#x = x[sr:2 * sr]\n",
    "\n",
    "###############################################################################\n",
    "# Once the recording is in memory, we normalize it.\n",
    "x = train_epochs[0]['P001_S001_001_epoch0'][7]\n",
    "x = x / np.max(np.abs(x))\n",
    "\n",
    "###############################################################################\n",
    "# We are now ready to set up the parameters for the scattering transform.\n",
    "# First, the number of samples, `T`, is given by the size of our input `x`.\n",
    "# The averaging scale is specified as a power of two, `2**J`. Here, we set\n",
    "# `J = 6` to get an averaging, or maximum, scattering scale of `2**6 = 64`\n",
    "# samples. Finally, we set the number of wavelets per octave, `Q`, to `16`.\n",
    "# This lets us resolve frequencies at a resolution of `1/16` octaves.\n",
    "\n",
    "T = x.shape[-1]\n",
    "print(T)\n",
    "J = 6\n",
    "Q = 16\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we are able to create the object which computes our scattering\n",
    "# transform, `scattering`.\n",
    "\n",
    "scattering = Scattering1D(J, T, Q)\n",
    "\n",
    "###############################################################################\n",
    "# Compute and display the scattering coefficients\n",
    "# -----------------------------------------------\n",
    "# Computing the scattering transform of a signal is achieved using the\n",
    "# `__call__` method of the `Scattering1D` class. The output is an array of\n",
    "# shape `(C, T)`. Here, `C` is the number of scattering coefficient outputs,\n",
    "# and `T` is the number of samples along the time axis. This is typically much\n",
    "# smaller than the number of input samples since the scattering transform\n",
    "# performs an average in time and subsamples the result to save memory.\n",
    "\n",
    "Sx = scattering(x)\n",
    "print('Sx shape: ', Sx.shape)\n",
    "###############################################################################\n",
    "# To display the scattering coefficients, we must first identify which belong\n",
    "# to each order (zeroth, first, or second). We do this by extracting the `meta`\n",
    "# information from the scattering object and constructing masks for each order.\n",
    "\n",
    "meta = scattering.meta()\n",
    "order0 = np.where(meta['order'] == 0)\n",
    "order1 = np.where(meta['order'] == 1)\n",
    "order2 = np.where(meta['order'] == 2)\n",
    "\n",
    "###############################################################################\n",
    "# First, we plot the original signal `x`.\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.plot(x)\n",
    "plt.title('Original signal')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# We now plot the zeroth-order scattering coefficient, which is simply an\n",
    "# average of the original signal at the scale `2**J`.\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(Sx[order0][0])\n",
    "plt.title('Zeroth-order scattering')\n",
    "plt.show()\n",
    "print('len order 0: ', Sx[order0].shape)\n",
    "\n",
    "###############################################################################\n",
    "# We then plot the first-order coefficients, which are arranged along time\n",
    "# and log-frequency.\n",
    "\n",
    "plt.imshow(Sx[order1], aspect='auto')\n",
    "plt.title('First-order scattering')\n",
    "plt.show()\n",
    "print('len order 1: ', Sx[order1].shape)\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we plot the second-order scattering coefficients. These are also\n",
    "# organized aling time, but has two log-frequency indices: one first-order\n",
    "# frequency and one second-order frequency. Here, both indices are mixed along\n",
    "# the vertical axis.\n",
    "\n",
    "plt.imshow(Sx[order2], aspect='auto')\n",
    "plt.title('Second-order scattering')\n",
    "plt.show()\n",
    "print('len order 2: ', Sx[order2].shape)\n",
    "print(Sx.shape)\n",
    "\n",
    "Sx= np.mean(Sx, axis=-1)\n",
    "Sx = np.ndarray.flatten(Sx)\n",
    "print(np.transpose(Sx.shape))\n",
    "print(np.transpose(Sx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = features.kymatio_wave_scattering(train_epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = features.kymatio_wave_scattering(test_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ica data')\n",
    "cls.knn_classification(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ica data')\n",
    "print(cls.svm_classification(x_train, x_test, y_train, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6df28382c6e70c1c1d3c02fa7b17b6f3b6fcf9f5d22d2410beebd122bfaf45e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
