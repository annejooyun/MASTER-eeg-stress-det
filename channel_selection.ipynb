{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset, load_labels, convert_to_epochs, load_channels\n",
    "from features import time_series_features, nonlinear_features, entropy_features, hjorth_features, freq_band_features\n",
    "from classifiers import LR, KNN, SVM, NN\n",
    "import variables as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing ICA filtered two times\n",
    "\n",
    "dataset_ica_2_ = load_dataset(data_type=\"ica2\", test_type=\"Arithmetic\")\n",
    "\n",
    "channels = load_channels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_1 = ['Fp1', 'C3', 'T7','O1', 'O2' 'T8', 'C4', 'Fp2']\n",
    "channels_2 = ['F3', 'C3', 'P3', 'O1', 'O2', 'P4', 'C4', 'F4']\n",
    "channels_3 = ['Fp1', 'C3', 'P7', 'O1', 'O2', 'P8', 'C4', 'Fp2']\n",
    "channels_4 = ['Cz', 'Fz', 'P3', 'Pz', 'PO9', 'Oz', 'PO10', 'P4']\n",
    "\n",
    "n_sub_ch = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(data, all_channels, subset_channels):\n",
    "    subset_data = np.empty((120, 8, 3200))\n",
    "\n",
    "    j = 0\n",
    "    for i in range(len(all_channels)):\n",
    "        if j < (n_sub_ch + 1) and all_channels[i] in subset_channels:\n",
    "            subset_data[:,j,:] = data[:,i,:]\n",
    "            j+=1\n",
    "    return subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(array):\n",
    "    x = np.isnan(array)\n",
    "    if True in x:\n",
    "        print('NAN in array')\n",
    "        return 0\n",
    "    print('No NAN found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NAN found\n",
      "No NAN found\n",
      "No NAN found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subset_data_1 = get_subset(dataset_ica_2_, channels, channels_1)\n",
    "subset_data_2 = get_subset(dataset_ica_2_, channels, channels_2)\n",
    "subset_data_3 = get_subset(dataset_ica_2_, channels, channels_3)\n",
    "subset_data_4 = get_subset(dataset_ica_2_, channels, channels_4)\n",
    "\n",
    "\n",
    "check_nan(subset_data_1[0])\n",
    "check_nan(subset_data_1[0])\n",
    "check_nan(subset_data_1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 25, 8, 128)\n",
      "No NAN found\n",
      "(120, 25, 8, 128)\n",
      "No NAN found\n",
      "(120, 25, 8, 128)\n",
      "No NAN found\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = convert_to_epochs(subset_data_2, n_sub_ch, v.SFREQ)\n",
    "features_2 = time_series_features(dataset_2, n_sub_ch)\n",
    "data_2 = features_2\n",
    "check_nan(data_2)\n",
    "\n",
    "dataset_3 = convert_to_epochs(subset_data_3, n_sub_ch, v.SFREQ)\n",
    "features_3 = time_series_features(dataset_3, n_sub_ch)\n",
    "data_3 = features_3\n",
    "check_nan(data_3)\n",
    "\n",
    "dataset_4 = convert_to_epochs(subset_data_4, n_sub_ch, v.SFREQ)\n",
    "features_4 = time_series_features(dataset_4, n_sub_ch)\n",
    "data_4 = features_4\n",
    "check_nan(data_4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "labels = load_labels()\n",
    "label = pd.concat([labels['t1_math'], labels['t2_math'],\n",
    "                  labels['t3_math']]).to_numpy()\n",
    "label = label.repeat(dataset_1.shape[1])\n",
    "\n",
    "print(np.isnan(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel subset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.62      0.61       527\n",
      "        True       0.54      0.51      0.53       463\n",
      "\n",
      "    accuracy                           0.57       990\n",
      "   macro avg       0.57      0.57      0.57       990\n",
      "weighted avg       0.57      0.57      0.57       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[329 198]\n",
      " [226 237]]\n",
      "\n",
      " Sensitivity: 0.5927927927927928\n",
      "\n",
      " Specificity: 0.5448275862068965\n",
      "Channel subset 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.60      0.58       527\n",
      "        True       0.50      0.46      0.48       463\n",
      "\n",
      "    accuracy                           0.53       990\n",
      "   macro avg       0.53      0.53      0.53       990\n",
      "weighted avg       0.53      0.53      0.53       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[317 210]\n",
      " [252 211]]\n",
      "\n",
      " Sensitivity: 0.5571177504393673\n",
      "\n",
      " Specificity: 0.501187648456057\n",
      "Channel subset 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.64      0.62       527\n",
      "        True       0.56      0.51      0.53       463\n",
      "\n",
      "    accuracy                           0.58       990\n",
      "   macro avg       0.58      0.58      0.58       990\n",
      "weighted avg       0.58      0.58      0.58       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[339 188]\n",
      " [227 236]]\n",
      "\n",
      " Sensitivity: 0.598939929328622\n",
      "\n",
      " Specificity: 0.5566037735849056\n"
     ]
    }
   ],
   "source": [
    "print('Channel subset 2')\n",
    "LR(data_2, label)\n",
    "\n",
    "print('Channel subset 3')\n",
    "LR(data_3, label)\n",
    "\n",
    "print('Channel subset 4')\n",
    "LR(data_4, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel subset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.74      0.65       311\n",
      "        True       0.60      0.42      0.49       289\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.59      0.58      0.57       600\n",
      "weighted avg       0.59      0.58      0.57       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[231  80]\n",
      " [169 120]]\n",
      "\n",
      " Sensitivity: 0.5775\n",
      "\n",
      " Specificity: 0.6\n",
      "Channel subset 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.66      0.64       311\n",
      "        True       0.61      0.59      0.60       289\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.62      0.62      0.62       600\n",
      "weighted avg       0.62      0.62      0.62       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[204 107]\n",
      " [119 170]]\n",
      "\n",
      " Sensitivity: 0.631578947368421\n",
      "\n",
      " Specificity: 0.6137184115523465\n",
      "Channel subset 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.65      0.65       311\n",
      "        True       0.62      0.62      0.62       289\n",
      "\n",
      "    accuracy                           0.64       600\n",
      "   macro avg       0.64      0.64      0.64       600\n",
      "weighted avg       0.64      0.64      0.64       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[202 109]\n",
      " [109 180]]\n",
      "\n",
      " Sensitivity: 0.6495176848874598\n",
      "\n",
      " Specificity: 0.6228373702422145\n"
     ]
    }
   ],
   "source": [
    "print('Channel subset 2')\n",
    "KNN(data_2, label)\n",
    "\n",
    "print('Channel subset 3')\n",
    "KNN(data_3, label)\n",
    "\n",
    "print('Channel subset 4')\n",
    "KNN(data_4, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel subset 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.75      0.72       311\n",
      "        True       0.71      0.66      0.68       289\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.71      0.70      0.70       600\n",
      "weighted avg       0.71      0.70      0.70       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[232  79]\n",
      " [ 98 191]]\n",
      "\n",
      " Sensitivity: 0.703030303030303\n",
      "\n",
      " Specificity: 0.7074074074074074\n",
      "Channel subset 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.78      0.76       311\n",
      "        True       0.75      0.72      0.74       289\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[242  69]\n",
      " [ 80 209]]\n",
      "\n",
      " Sensitivity: 0.7515527950310559\n",
      "\n",
      " Specificity: 0.7517985611510791\n",
      "Channel subset 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.66      0.68       311\n",
      "        True       0.66      0.69      0.67       289\n",
      "\n",
      "    accuracy                           0.68       600\n",
      "   macro avg       0.68      0.68      0.68       600\n",
      "weighted avg       0.68      0.68      0.68       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[206 105]\n",
      " [ 89 200]]\n",
      "\n",
      " Sensitivity: 0.6983050847457627\n",
      "\n",
      " Specificity: 0.6557377049180327\n"
     ]
    }
   ],
   "source": [
    "print('Channel subset 2')\n",
    "SVM(data_2, label)\n",
    "\n",
    "print('Channel subset 3')\n",
    "SVM(data_3, label)\n",
    "\n",
    "print('Channel subset 4')\n",
    "SVM(data_4, label)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824278683c81e2d79923c12750dfea42912982f00ff363fc366281626f07813b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
