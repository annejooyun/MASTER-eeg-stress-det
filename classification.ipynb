{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset, load_ica_dataset, load_labels, convert_to_epochs\n",
    "from features import time_series_features, nonlinear_features, entropy_features, hjorth_features, freq_band_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "channels = 32\n",
    "sfreq = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered from SAM40\n",
    "dataset_ = load_dataset(raw = False)\n",
    "dataset = convert_to_epochs(dataset_, channels, sfreq)\n",
    "\n",
    "#ICA filtered\n",
    "dataset_ica_ = load_ica_dataset()\n",
    "dataset_ica = convert_to_epochs(dataset_ica_, channels, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 25, 32, 128)\n",
      "(120, 25, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "features = time_series_features(dataset, channels)\n",
    "features_ica = time_series_features(dataset_ica, channels)\n",
    "# freq_bands = np.array([1, 4, 8, 13, 31, 50])\n",
    "# features = freq_band_features(dataset, channels, sfreq, freq_bands)\n",
    "# features = nonlinear_features(dataset, channels)\n",
    "# features = hjorth_features(dataset, channels, sfreq)\n",
    "# features = entropy_features(dataset, channels, sfreq)\n",
    "data = features\n",
    "data_ica = features_ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()\n",
    "label = pd.concat([labels['t1_math'], labels['t2_math'],\n",
    "                  labels['t3_math']]).to_numpy()\n",
    "label = label.repeat(dataset.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(data, label):\n",
    "    K.clear_session()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    lr_clf = LogisticRegression(max_iter=1000).fit(x_train, y_train)\n",
    "    y_pred = lr_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    scores_lr = lr_clf.score(x_test, y_test)\n",
    "    precision_lr = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "    recall_lr = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "    f1_score_lr = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "    print('accuracy is:', scores_lr)\n",
    "    print('precision is:', precision_lr)\n",
    "    print('recall is:', recall_lr)\n",
    "    print('f1_score is:', f1_score_lr)\n",
    "    metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(data, label):\n",
    "    K.clear_session()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.33, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    neigh_clf = KNeighborsClassifier(n_neighbors=2)\n",
    "    neigh_clf.fit(x_train, y_train)\n",
    "    y_pred = neigh_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    scores_neigh = neigh_clf.score(x_test, y_test)\n",
    "    precision_neigh = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "    recall_neigh = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "    f1_score_neigh = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "    print('accuracy is:', scores_neigh)\n",
    "    print('precision is:', precision_neigh)\n",
    "    print('recall is:', recall_neigh)\n",
    "    print('f1_score is:', f1_score_neigh)\n",
    "    metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(data, label):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "    svm_clf = SVC(C=10, kernel='rbf')\n",
    "    svm_clf.fit(x_train, y_train)\n",
    "    y_pred = svm_clf.predict(x_test)\n",
    "    y_pred_train = svm_clf.predict(x_train)\n",
    "    y_true = y_test\n",
    "\n",
    "    scores_svm_train = svm_clf.score(x_train, y_train)\n",
    "    precision_svm_train = metrics.precision_score(y_train, y_pred_train, average='macro')\n",
    "    recall_svm_train = metrics.recall_score(y_train, y_pred_train, average='micro')\n",
    "    f1_score_svm_train = metrics.f1_score(y_train, y_pred_train, average='weighted')\n",
    "    print('accuracy is:', scores_svm_train)\n",
    "    print('precision is:', precision_svm_train)\n",
    "    print('recall is:', precision_svm_train)\n",
    "    print('f1_score is:', f1_score_svm_train)\n",
    "    metrics.confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "accuracy is: 0.6818181818181818\n",
      "precision is: 0.6807722500245315\n",
      "recall is: 0.6818181818181818\n",
      "f1_score is: 0.6820079922226571\n",
      "\n",
      "ICA filtered data\n",
      "accuracy is: 0.5898989898989899\n",
      "precision is: 0.589167799870141\n",
      "recall is: 0.5898989898989899\n",
      "f1_score is: 0.5902679350747364\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "LinearRegression(data,label)\n",
    "print('\\nICA filtered data')\n",
    "LinearRegression(data_ica,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "accuracy is: 0.6343434343434343\n",
      "precision is: 0.6545246070463582\n",
      "recall is: 0.6343434343434343\n",
      "f1_score is: 0.6119252044252045\n",
      "\n",
      "ICA filtered data\n",
      "accuracy is: 0.5727272727272728\n",
      "precision is: 0.5758361534742671\n",
      "recall is: 0.5727272727272728\n",
      "f1_score is: 0.5433042081000828\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "KNN(data,label)\n",
    "print('\\nICA filtered data')\n",
    "KNN(data_ica,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "accuracy is: 0.8169154228855722\n",
      "precision is: 0.8165542710340399\n",
      "recall is: 0.8165542710340399\n",
      "f1_score is: 0.8169499129955898\n",
      "\n",
      "ICA filtered data\n",
      "accuracy is: 0.7233830845771144\n",
      "precision is: 0.7264640599969714\n",
      "recall is: 0.7264640599969714\n",
      "f1_score is: 0.7230822773350355\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "SVM(data,label)\n",
    "print('\\nICA filtered data')\n",
    "SVM(data_ica,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_ica, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 6, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |?                 |layers\n",
      "224               |?                 |units_0\n",
      "relu              |?                 |act_0\n",
      "896               |?                 |units_1\n",
      "sigmoid           |?                 |act_1\n",
      "0.0001            |?                 |learning_rate\n",
      "\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 2s 13ms/step - loss: 0.6896 - accuracy: 0.5372 - val_loss: 0.6749 - val_accuracy: 0.5550\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.5956 - val_loss: 0.6653 - val_accuracy: 0.5917\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.6294 - val_loss: 0.6540 - val_accuracy: 0.6150\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.6683 - val_loss: 0.6394 - val_accuracy: 0.6350\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.6828 - val_loss: 0.6332 - val_accuracy: 0.6517\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.6950 - val_loss: 0.6202 - val_accuracy: 0.6700\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7289 - val_loss: 0.6069 - val_accuracy: 0.6800\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5561 - accuracy: 0.7294 - val_loss: 0.6045 - val_accuracy: 0.6900\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5392 - accuracy: 0.7650 - val_loss: 0.5809 - val_accuracy: 0.7117\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7917 - val_loss: 0.5745 - val_accuracy: 0.7067\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.8044 - val_loss: 0.5946 - val_accuracy: 0.6733\n",
      "Epoch 12/50\n",
      "52/57 [==========================>...] - ETA: 0s - loss: 0.4561 - accuracy: 0.8263"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to rename: .\\untitled_project\\trial_0\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\untitled_project\\trial_0\\checkpoint.data-00000-of-00001 : Prosessen får ikke tilgang til filen fordi den brukes av en annen prosess.\r\n; Broken pipe [Op:MergeV2Checkpoints]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5236\\600842376.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: .\\untitled_project\\trial_0\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\untitled_project\\trial_0\\checkpoint.data-00000-of-00001 : Prosessen får ikke tilgang til filen fordi den brukes av en annen prosess.\r\n; Broken pipe [Op:MergeV2Checkpoints]"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824278683c81e2d79923c12750dfea42912982f00ff363fc366281626f07813b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
