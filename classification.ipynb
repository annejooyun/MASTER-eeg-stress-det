{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset, load_ica_dataset, load_labels, convert_to_epochs\n",
    "from features import time_series_features, nonlinear_features, entropy_features, hjorth_features, freq_band_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "channels = 32\n",
    "sfreq = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered from SAM40\n",
    "dataset_ = load_dataset(raw = False)\n",
    "dataset = convert_to_epochs(dataset_, channels, sfreq)\n",
    "\n",
    "#ICA filtered\n",
    "dataset_ica_ = load_ica_dataset(round=1)\n",
    "dataset_ica = convert_to_epochs(dataset_ica_, channels, sfreq)\n",
    "\n",
    "#ICA filtered two times\n",
    "dataset_ica_2_ = load_ica_dataset(round=2)\n",
    "dataset_ica_2 = convert_to_epochs(dataset_ica_2_, channels, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 25, 32, 128)\n",
      "(120, 25, 32, 128)\n",
      "(120, 25, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "features = time_series_features(dataset, channels)\n",
    "features_ica = time_series_features(dataset_ica, channels)\n",
    "features_ica_2 = time_series_features(dataset_ica_2, channels)\n",
    "# freq_bands = np.array([1, 4, 8, 13, 31, 50])\n",
    "# features = freq_band_features(dataset, channels, sfreq, freq_bands)\n",
    "# features = nonlinear_features(dataset, channels)\n",
    "# features = hjorth_features(dataset, channels, sfreq)\n",
    "# features = entropy_features(dataset, channels, sfreq)\n",
    "data = features\n",
    "data_ica = features_ica\n",
    "data_ica_2 = features_ica_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()\n",
    "label = pd.concat([labels['t1_math'], labels['t2_math'],\n",
    "                  labels['t3_math']]).to_numpy()\n",
    "label = label.repeat(dataset.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(data, label):\n",
    "    K.clear_session()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    lr_clf = LogisticRegression(max_iter=1000).fit(x_train, y_train)\n",
    "    y_pred = lr_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    scores_lr = lr_clf.score(x_test, y_test)\n",
    "    precision_lr = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "    recall_lr = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "    f1_score_lr = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(data, label):\n",
    "    K.clear_session()\n",
    "    x, x_test, y, y_test = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x = scaler.transform(x)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    param_grid = {\n",
    "        'leaf_size': range(50),\n",
    "        'n_neighbors': range(1, 10),\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "    split_index = [-1 if x in range(len(x_train)) else 0 for x in range(len(x))]\n",
    "    ps = PredefinedSplit(test_fold=split_index)\n",
    "    knn_clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ps, refit=True)\n",
    "    knn_clf.fit(x, y)\n",
    "\n",
    "    y_pred = knn_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(data, label):\n",
    "    x, x_test, y, y_test = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    split_index = [-1 if x in range(len(x_train)) else 0 for x in range(len(x))]\n",
    "    ps = PredefinedSplit(test_fold=split_index)\n",
    "    clf = GridSearchCV(SVC(), param_grid, cv=ps, refit=True)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.69      0.70       527\n",
      "        True       0.66      0.67      0.66       463\n",
      "\n",
      "    accuracy                           0.68       990\n",
      "   macro avg       0.68      0.68      0.68       990\n",
      "weighted avg       0.68      0.68      0.68       990\n",
      "\n",
      "[[364 163]\n",
      " [152 311]]\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.60      0.61       527\n",
      "        True       0.56      0.58      0.57       463\n",
      "\n",
      "    accuracy                           0.59       990\n",
      "   macro avg       0.59      0.59      0.59       990\n",
      "weighted avg       0.59      0.59      0.59       990\n",
      "\n",
      "[[314 213]\n",
      " [193 270]]\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.67      0.66       527\n",
      "        True       0.62      0.61      0.61       463\n",
      "\n",
      "    accuracy                           0.64       990\n",
      "   macro avg       0.64      0.64      0.64       990\n",
      "weighted avg       0.64      0.64      0.64       990\n",
      "\n",
      "[[351 176]\n",
      " [181 282]]\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "LinearRegression(data,label)\n",
    "print('\\nICA filtered data')\n",
    "LinearRegression(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "LinearRegression(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.77      0.78       311\n",
      "        True       0.76      0.78      0.77       289\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.77      0.78      0.77       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[241  70]\n",
      " [ 65 224]]\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.65      0.64       311\n",
      "        True       0.61      0.59      0.60       289\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.62      0.62      0.62       600\n",
      "weighted avg       0.62      0.62      0.62       600\n",
      "\n",
      "[[202 109]\n",
      " [118 171]]\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.73      0.71       311\n",
      "        True       0.69      0.64      0.66       289\n",
      "\n",
      "    accuracy                           0.69       600\n",
      "   macro avg       0.69      0.69      0.69       600\n",
      "weighted avg       0.69      0.69      0.69       600\n",
      "\n",
      "[[228  83]\n",
      " [104 185]]\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "KNN(data,label)\n",
    "print('\\nICA filtered data')\n",
    "KNN(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "KNN(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.95      0.96       311\n",
      "        True       0.95      0.97      0.96       289\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[296  15]\n",
      " [ 10 279]]\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.84      0.76       311\n",
      "        True       0.78      0.61      0.68       289\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.72       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "[[262  49]\n",
      " [113 176]]\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.92      0.90       311\n",
      "        True       0.91      0.87      0.89       289\n",
      "\n",
      "    accuracy                           0.89       600\n",
      "   macro avg       0.89      0.89      0.89       600\n",
      "weighted avg       0.89      0.89      0.89       600\n",
      "\n",
      "[[286  25]\n",
      " [ 39 250]]\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "SVM(data,label)\n",
    "print('\\nICA filtered data')\n",
    "SVM(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "SVM(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 41s]\n",
      "val_accuracy: 0.565833330154419\n",
      "\n",
      "Best val_accuracy So Far: 0.8816666603088379\n",
      "Total elapsed time: 00h 09m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "accuracy is: 0.824999988079071\n",
      "precision is: 0.8261298421807748\n",
      "recall is: 0.825\n",
      "f1_score is: 0.8246763408735239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[267,  44],\n",
       "       [ 61, 228]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 57s]\n",
      "val_accuracy: 0.7450000047683716\n",
      "\n",
      "Best val_accuracy So Far: 0.8266666531562805\n",
      "Total elapsed time: 00h 10m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "19/19 [==============================] - 0s 8ms/step\n",
      "accuracy is: 0.846666693687439\n",
      "precision is: 0.846427499416349\n",
      "recall is: 0.8466666666666667\n",
      "f1_score is: 0.8466973609581956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[263,  48],\n",
       "       [ 44, 245]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_ica, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 56s]\n",
      "val_accuracy: 0.8974999785423279\n",
      "\n",
      "Best val_accuracy So Far: 0.8974999785423279\n",
      "Total elapsed time: 00h 09m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "accuracy is: 0.8949999809265137\n",
      "precision is: 0.8957839939228741\n",
      "recall is: 0.895\n",
      "f1_score is: 0.894893803756363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[285,  26],\n",
       "       [ 37, 252]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_ica_2, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824278683c81e2d79923c12750dfea42912982f00ff363fc366281626f07813b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
