{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset, load_labels, convert_to_epochs\n",
    "from features import time_series_features, nonlinear_features, entropy_features, hjorth_features, freq_band_features\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "channels = 32\n",
    "sfreq = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered from SAM40\n",
    "dataset_ = load_dataset(data_type=\"filtered\", test_type=\"Arithmetic\")\n",
    "dataset = convert_to_epochs(dataset_, channels, sfreq)\n",
    "\n",
    "#ICA filtered\n",
    "dataset_ica_ = load_dataset(data_type=\"ica1\", test_type=\"Arithmetic\")\n",
    "dataset_ica = convert_to_epochs(dataset_ica_, channels, sfreq)\n",
    "\n",
    "#ICA filtered two times\n",
    "dataset_ica_2_ = load_dataset(data_type=\"ica2\", test_type=\"Arithmetic\")\n",
    "dataset_ica_2 = convert_to_epochs(dataset_ica_2_, channels, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 25, 32, 128)\n",
      "(120, 25, 32, 128)\n",
      "(120, 25, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "features = time_series_features(dataset, channels)\n",
    "features_ica = time_series_features(dataset_ica, channels)\n",
    "features_ica_2 = time_series_features(dataset_ica_2, channels)\n",
    "# freq_bands = np.array([1, 4, 8, 13, 31, 50])\n",
    "# features = freq_band_features(dataset, channels, sfreq, freq_bands)\n",
    "# features = nonlinear_features(dataset, channels)\n",
    "# features = hjorth_features(dataset, channels, sfreq)\n",
    "# features = entropy_features(dataset, channels, sfreq)\n",
    "data = features\n",
    "data_ica = features_ica\n",
    "data_ica_2 = features_ica_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()\n",
    "label = pd.concat([labels['t1_math'], labels['t2_math'],\n",
    "                  labels['t3_math']]).to_numpy()\n",
    "label = label.repeat(dataset.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(data, label):\n",
    "    K.clear_session()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    lr_clf = LogisticRegression(max_iter=1000).fit(x_train, y_train)\n",
    "    y_pred = lr_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    scores_lr = lr_clf.score(x_test, y_test)\n",
    "    compute_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(data, label):\n",
    "    K.clear_session()\n",
    "    x, x_test, y, y_test = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x = scaler.transform(x)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    param_grid = {\n",
    "        'leaf_size': range(50),\n",
    "        'n_neighbors': range(1, 10),\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "    split_index = [-1 if x in range(len(x_train)) else 0 for x in range(len(x))]\n",
    "    ps = PredefinedSplit(test_fold=split_index)\n",
    "    knn_clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ps, refit=True)\n",
    "    knn_clf.fit(x, y)\n",
    "\n",
    "    y_pred = knn_clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    compute_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(data, label):\n",
    "    x, x_test, y, y_test = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    split_index = [-1 if x in range(len(x_train)) else 0 for x in range(len(x))]\n",
    "    ps = PredefinedSplit(test_fold=split_index)\n",
    "    clf = GridSearchCV(SVC(), param_grid, cv=ps, refit=True)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "    compute_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.69      0.70       527\n",
      "        True       0.66      0.67      0.66       463\n",
      "\n",
      "    accuracy                           0.68       990\n",
      "   macro avg       0.68      0.68      0.68       990\n",
      "weighted avg       0.68      0.68      0.68       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[364 163]\n",
      " [152 311]]\n",
      "\n",
      " Sensitivity: 0.7054263565891473\n",
      "\n",
      " Specificity: 0.6561181434599156\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.60      0.61       527\n",
      "        True       0.56      0.58      0.57       463\n",
      "\n",
      "    accuracy                           0.59       990\n",
      "   macro avg       0.59      0.59      0.59       990\n",
      "weighted avg       0.59      0.59      0.59       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[314 213]\n",
      " [193 270]]\n",
      "\n",
      " Sensitivity: 0.6193293885601578\n",
      "\n",
      " Specificity: 0.5590062111801242\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.67      0.66       527\n",
      "        True       0.62      0.61      0.61       463\n",
      "\n",
      "    accuracy                           0.64       990\n",
      "   macro avg       0.64      0.64      0.64       990\n",
      "weighted avg       0.64      0.64      0.64       990\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[351 176]\n",
      " [181 282]]\n",
      "\n",
      " Sensitivity: 0.6597744360902256\n",
      "\n",
      " Specificity: 0.6157205240174672\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "LinearRegression(data,label)\n",
    "print('\\nICA filtered data')\n",
    "LinearRegression(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "LinearRegression(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.77      0.78       311\n",
      "        True       0.76      0.78      0.77       289\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.77      0.78      0.77       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[241  70]\n",
      " [ 65 224]]\n",
      "\n",
      " Sensitivity: 0.7875816993464052\n",
      "\n",
      " Specificity: 0.7619047619047619\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.65      0.64       311\n",
      "        True       0.61      0.59      0.60       289\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.62      0.62      0.62       600\n",
      "weighted avg       0.62      0.62      0.62       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[202 109]\n",
      " [118 171]]\n",
      "\n",
      " Sensitivity: 0.63125\n",
      "\n",
      " Specificity: 0.6107142857142858\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.73      0.71       311\n",
      "        True       0.69      0.64      0.66       289\n",
      "\n",
      "    accuracy                           0.69       600\n",
      "   macro avg       0.69      0.69      0.69       600\n",
      "weighted avg       0.69      0.69      0.69       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[228  83]\n",
      " [104 185]]\n",
      "\n",
      " Sensitivity: 0.6867469879518072\n",
      "\n",
      " Specificity: 0.6902985074626866\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "KNN(data,label)\n",
    "print('\\nICA filtered data')\n",
    "KNN(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "KNN(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.95      0.96       311\n",
      "        True       0.95      0.97      0.96       289\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[296  15]\n",
      " [ 10 279]]\n",
      "\n",
      " Sensitivity: 0.9673202614379085\n",
      "\n",
      " Specificity: 0.9489795918367347\n",
      "\n",
      "ICA filtered data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.84      0.76       311\n",
      "        True       0.78      0.61      0.68       289\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.72       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[262  49]\n",
      " [113 176]]\n",
      "\n",
      " Sensitivity: 0.6986666666666667\n",
      "\n",
      " Specificity: 0.7822222222222223\n",
      "\n",
      "ICA filtered data round 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.92      0.90       311\n",
      "        True       0.91      0.87      0.89       289\n",
      "\n",
      "    accuracy                           0.89       600\n",
      "   macro avg       0.89      0.89      0.89       600\n",
      "weighted avg       0.89      0.89      0.89       600\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "[[286  25]\n",
      " [ 39 250]]\n",
      "\n",
      " Sensitivity: 0.88\n",
      "\n",
      " Specificity: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print('Filtered data')\n",
    "SVM(data,label)\n",
    "print('\\nICA filtered data')\n",
    "SVM(data_ica,label)\n",
    "print('\\nICA filtered data round 2')\n",
    "SVM(data_ica_2,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 6, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |?                 |layers\n",
      "896               |?                 |units_0\n",
      "sigmoid           |?                 |act_0\n",
      "736               |?                 |units_1\n",
      "relu              |?                 |act_1\n",
      "0.001             |?                 |learning_rate\n",
      "\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 2s 18ms/step - loss: 0.7074 - accuracy: 0.5161 - val_loss: 0.6929 - val_accuracy: 0.5450\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.6929 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5450\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5450\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6927 - accuracy: 0.5206 - val_loss: 0.6917 - val_accuracy: 0.5450\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.5206 - val_loss: 0.6915 - val_accuracy: 0.5450\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6925 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5450\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6911 - val_accuracy: 0.5450\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6909 - val_accuracy: 0.5450\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6908 - val_accuracy: 0.5450\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6908 - val_accuracy: 0.5450\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6907 - val_accuracy: 0.5450\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6907 - val_accuracy: 0.5450\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6905 - val_accuracy: 0.5450\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6905 - val_accuracy: 0.5450\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5450\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5450\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6905 - val_accuracy: 0.5450\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6905 - val_accuracy: 0.5450\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6902 - val_accuracy: 0.5450\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6902 - val_accuracy: 0.5450\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.7029 - accuracy: 0.5494 - val_loss: 0.6645 - val_accuracy: 0.5483\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5283 - val_loss: 0.6855 - val_accuracy: 0.5450\n",
      "Epoch 3/50\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 0.6851 - accuracy: 0.5477"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to rename: .\\untitled_project\\trial_0\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\untitled_project\\trial_0\\checkpoint.data-00000-of-00001 : Prosessen får ikke tilgang til filen fordi den brukes av en annen prosess.\r\n; Broken pipe [Op:MergeV2Checkpoints]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11024\\3428026801.py\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_space_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: .\\untitled_project\\trial_0\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\untitled_project\\trial_0\\checkpoint.data-00000-of-00001 : Prosessen får ikke tilgang til filen fordi den brukes av en annen prosess.\r\n; Broken pipe [Op:MergeV2Checkpoints]"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(metrics.classification_report(y_true, y_pred))\n",
    "print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 57s]\n",
      "val_accuracy: 0.7450000047683716\n",
      "\n",
      "Best val_accuracy So Far: 0.8266666531562805\n",
      "Total elapsed time: 00h 10m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "19/19 [==============================] - 0s 8ms/step\n",
      "accuracy is: 0.846666693687439\n",
      "precision is: 0.846427499416349\n",
      "recall is: 0.8466666666666667\n",
      "f1_score is: 0.8466973609581956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[263,  48],\n",
       "       [ 44, 245]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_ica, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 56s]\n",
      "val_accuracy: 0.8974999785423279\n",
      "\n",
      "Best val_accuracy So Far: 0.8974999785423279\n",
      "Total elapsed time: 00h 09m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "accuracy is: 0.8949999809265137\n",
      "precision is: 0.8957839939228741\n",
      "recall is: 0.895\n",
      "f1_score is: 0.894893803756363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[285,  26],\n",
       "       [ 37, 252]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_ica_2, y_v, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "      model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), 32, 1024, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', name='out'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.adam_v2.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x_train, y_train, epochs = 50, validation_data= [x_val, y_val])\n",
    "\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)\n",
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824278683c81e2d79923c12750dfea42912982f00ff363fc366281626f07813b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
