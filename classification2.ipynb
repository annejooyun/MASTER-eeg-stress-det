{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "from utils.data import extract_eeg_data, multi_to_binary_classification, split_dataset, dict_to_arr\n",
    "from utils.labels import get_pss_labels, get_stai_labels\n",
    "from utils.valid_recs import get_valid_recs\n",
    "from features import all_features, hjorth_features\n",
    "from classifiers import knn_classification, svm_classification, cnn_classification, EEGNet_classification_2\n",
    "import utils.variables as v\n",
    "\n",
    "from EEGModels import EEGNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:1) Failed to read data for recording P006_S002_001\n",
      "ERROR:root:1) Failed to read data for recording P006_S002_002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out invalid recordings\n",
      "\n",
      "Data/ICA_data\\sub-P010_ses-S001_run-001.mat not valid\n",
      "Data/ICA_data\\sub-P013_ses-S001_run-001.mat not valid\n",
      "Data/ICA_data\\sub-P013_ses-S001_run-002.mat not valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:1) Failed to read data for recording P028_S001_001\n",
      "ERROR:root:1) Failed to read data for recording P028_S001_002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/ICA_data\\sub-P020_ses-S001_run-001.mat not valid\n",
      "Data/ICA_data\\sub-P023_ses-S002_run-002.mat not valid\n",
      "Returning valid recordings\n",
      "\n",
      "Valid recs ['P001_S001_001', 'P001_S001_002', 'P001_S002_001', 'P001_S002_002', 'P002_S001_001', 'P002_S001_002', 'P002_S002_001', 'P002_S002_002', 'P003_S001_001', 'P003_S001_002', 'P003_S002_001', 'P003_S002_002', 'P004_S001_001', 'P004_S001_002', 'P004_S002_001', 'P004_S002_002', 'P005_S001_001', 'P005_S001_002', 'P005_S002_001', 'P005_S002_002', 'P006_S001_001', 'P006_S001_002', 'P007_S001_001', 'P007_S001_002', 'P007_S002_001', 'P007_S002_002', 'P008_S001_001', 'P008_S001_002', 'P008_S002_001', 'P008_S002_002', 'P009_S001_001', 'P009_S001_002', 'P009_S002_001', 'P009_S002_002', 'P010_S001_002', 'P010_S002_001', 'P010_S002_002', 'P011_S001_001', 'P011_S001_002', 'P011_S002_001', 'P011_S002_002', 'P012_S001_001', 'P012_S001_002', 'P012_S002_001', 'P012_S002_002', 'P013_S002_001', 'P013_S002_002', 'P014_S001_001', 'P014_S001_002', 'P014_S002_001', 'P014_S002_002', 'P015_S001_001', 'P015_S001_002', 'P015_S002_001', 'P015_S002_002', 'P016_S001_001', 'P016_S001_002', 'P016_S002_001', 'P016_S002_002', 'P017_S001_001', 'P017_S001_002', 'P017_S002_001', 'P017_S002_002', 'P018_S001_001', 'P018_S001_002', 'P018_S002_001', 'P018_S002_002', 'P019_S001_001', 'P019_S001_002', 'P019_S002_001', 'P019_S002_002', 'P020_S001_002', 'P020_S002_001', 'P020_S002_002', 'P021_S001_001', 'P021_S001_002', 'P021_S002_001', 'P021_S002_002', 'P022_S001_001', 'P022_S001_002', 'P022_S002_001', 'P022_S002_002', 'P023_S001_001', 'P023_S001_002', 'P023_S002_001', 'P024_S001_001', 'P024_S001_002', 'P024_S002_001', 'P024_S002_002', 'P025_S001_001', 'P025_S001_002', 'P025_S002_001', 'P025_S002_002', 'P026_S001_001', 'P026_S001_002', 'P026_S002_001', 'P026_S002_002', 'P027_S001_001', 'P027_S001_002', 'P027_S002_001', 'P027_S002_002', 'P028_S002_001', 'P028_S002_002']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:2) Failed to read data for recording P028_S002_001\n",
      "ERROR:root:2) Failed to read data for recording P028_S002_002\n"
     ]
    }
   ],
   "source": [
    "valid_recs = get_valid_recs(data_type='init', output_type = 'np')\n",
    "print(f'Valid recs {valid_recs}')\n",
    "\n",
    "x_dict_ = extract_eeg_data(valid_recs, data_type='init', output_type='np')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SubjectNo  D1Y1  D2Y1  J1Y1  J2Y1\n",
      "0           1    26    30    29    31\n",
      "1           2    38    41    26    34\n",
      "2           3    58    56    36    35\n",
      "3           4    40    45    24    24\n",
      "4           5    25    31    38    37\n",
      "5           6    49    58     0     0\n",
      "6           7    56    50    28    28\n",
      "7           8    46    37    23    27\n",
      "8           9    41    47    27    22\n",
      "9          10    37    20    23    21\n",
      "10         11    50    49    31    47\n",
      "11         12    42    47    47    41\n",
      "12         13    35    35    28    33\n",
      "13         14    54    35    26    26\n",
      "14         15    51    55    33    42\n",
      "15         16    35    38    42    45\n",
      "16         17    37    35    24    20\n",
      "17         18    54    62    41    48\n",
      "18         19    47    52    30    36\n",
      "19         20    46    38    24    25\n",
      "20         21    44    54    33    39\n",
      "21         22    49    51    28    34\n",
      "22         23    56    53    33    28\n",
      "23         24    52    58    36    41\n",
      "24         25    48    62    29    56\n",
      "25         26    43    37    25    26\n",
      "26         27    52    41    41    34\n",
      "27         28     0     0    29    29\n",
      "Invalid value for label\n",
      "Invalid value for label\n",
      "Invalid record\n",
      "Invalid record\n",
      "Invalid record\n",
      "Invalid record\n",
      "Invalid record\n",
      "Invalid value for label\n",
      "Invalid value for label\n",
      "{'P001_S001_001': 0, 'P001_S001_002': 0, 'P001_S002_001': 0, 'P001_S002_002': 0, 'P002_S001_001': 1, 'P002_S001_002': 1, 'P002_S002_001': 0, 'P002_S002_002': 0, 'P003_S001_001': 2, 'P003_S001_002': 2, 'P003_S002_001': 0, 'P003_S002_002': 0, 'P004_S001_001': 1, 'P004_S001_002': 1, 'P004_S002_001': 0, 'P004_S002_002': 0, 'P005_S001_001': 0, 'P005_S001_002': 0, 'P005_S002_001': 1, 'P005_S002_002': 1, 'P006_S001_001': 2, 'P006_S001_002': 2, 'P007_S001_001': 2, 'P007_S001_002': 2, 'P007_S002_001': 0, 'P007_S002_002': 0, 'P008_S001_001': 2, 'P008_S001_002': 1, 'P008_S002_001': 0, 'P008_S002_002': 0, 'P009_S001_001': 1, 'P009_S001_002': 2, 'P009_S002_001': 0, 'P009_S002_002': 0, 'P010_S001_002': 0, 'P010_S002_001': 0, 'P010_S002_002': 0, 'P011_S001_001': 2, 'P011_S001_002': 2, 'P011_S002_001': 0, 'P011_S002_002': 2, 'P012_S001_001': 1, 'P012_S001_002': 2, 'P012_S002_001': 2, 'P012_S002_002': 1, 'P013_S002_001': 0, 'P013_S002_002': 0, 'P014_S001_001': 2, 'P014_S001_002': 0, 'P014_S002_001': 0, 'P014_S002_002': 0, 'P015_S001_001': 2, 'P015_S001_002': 2, 'P015_S002_001': 0, 'P015_S002_002': 1, 'P016_S001_001': 0, 'P016_S001_002': 1, 'P016_S002_001': 1, 'P016_S002_002': 1, 'P017_S001_001': 1, 'P017_S001_002': 0, 'P017_S002_001': 0, 'P017_S002_002': 0, 'P018_S001_001': 2, 'P018_S001_002': 2, 'P018_S002_001': 1, 'P018_S002_002': 2, 'P019_S001_001': 2, 'P019_S001_002': 2, 'P019_S002_001': 0, 'P019_S002_002': 0, 'P020_S001_002': 1, 'P020_S002_001': 0, 'P020_S002_002': 0, 'P021_S001_001': 1, 'P021_S001_002': 2, 'P021_S002_001': 0, 'P021_S002_002': 1, 'P022_S001_001': 2, 'P022_S001_002': 2, 'P022_S002_001': 0, 'P022_S002_002': 0, 'P023_S001_001': 2, 'P023_S001_002': 2, 'P023_S002_001': 0, 'P024_S001_001': 2, 'P024_S001_002': 2, 'P024_S002_001': 0, 'P024_S002_002': 1, 'P025_S001_001': 2, 'P025_S001_002': 2, 'P025_S002_001': 0, 'P025_S002_002': 2, 'P026_S001_001': 1, 'P026_S001_002': 1, 'P026_S002_001': 0, 'P026_S002_002': 0, 'P027_S001_001': 2, 'P027_S001_002': 1, 'P027_S002_001': 1, 'P027_S002_002': 0, 'P028_S002_001': 0, 'P028_S002_002': 0}\n"
     ]
    }
   ],
   "source": [
    "y_dict_ = get_stai_labels(valid_recs) \n",
    "#y_dict = get_pss_labels(valid_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Length of data after removing invalid labels: 103\n",
      " Lenght og labels after removing invalid labels: 103\n"
     ]
    }
   ],
   "source": [
    "print(f\" Length of data after removing invalid labels: {len(x_dict_)}\")\n",
    "print(f\" Lenght og labels after removing invalid labels: {len(y_dict_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The extracted keys : \n",
      "['P002_S001_001', 'P002_S001_002', 'P004_S001_001', 'P004_S001_002', 'P005_S002_001', 'P005_S002_002', 'P008_S001_002', 'P009_S001_001', 'P012_S001_001', 'P012_S002_002', 'P015_S002_002', 'P016_S001_002', 'P016_S002_001', 'P016_S002_002', 'P017_S001_001', 'P018_S002_001', 'P020_S001_002', 'P021_S001_001', 'P021_S002_002', 'P024_S002_002', 'P026_S001_001', 'P026_S001_002', 'P027_S001_002', 'P027_S002_001']\n",
      "\n",
      "Dictionary after removal of keys from y_dict: \n",
      " dict_keys(['P001_S001_001', 'P001_S001_002', 'P001_S002_001', 'P001_S002_002', 'P002_S002_001', 'P002_S002_002', 'P003_S001_001', 'P003_S001_002', 'P003_S002_001', 'P003_S002_002', 'P004_S002_001', 'P004_S002_002', 'P005_S001_001', 'P005_S001_002', 'P006_S001_001', 'P006_S001_002', 'P007_S001_001', 'P007_S001_002', 'P007_S002_001', 'P007_S002_002', 'P008_S001_001', 'P008_S002_001', 'P008_S002_002', 'P009_S001_002', 'P009_S002_001', 'P009_S002_002', 'P010_S001_002', 'P010_S002_001', 'P010_S002_002', 'P011_S001_001', 'P011_S001_002', 'P011_S002_001', 'P011_S002_002', 'P012_S001_002', 'P012_S002_001', 'P013_S002_001', 'P013_S002_002', 'P014_S001_001', 'P014_S001_002', 'P014_S002_001', 'P014_S002_002', 'P015_S001_001', 'P015_S001_002', 'P015_S002_001', 'P016_S001_001', 'P017_S001_002', 'P017_S002_001', 'P017_S002_002', 'P018_S001_001', 'P018_S001_002', 'P018_S002_002', 'P019_S001_001', 'P019_S001_002', 'P019_S002_001', 'P019_S002_002', 'P020_S002_001', 'P020_S002_002', 'P021_S001_002', 'P021_S002_001', 'P022_S001_001', 'P022_S001_002', 'P022_S002_001', 'P022_S002_002', 'P023_S001_001', 'P023_S001_002', 'P023_S002_001', 'P024_S001_001', 'P024_S001_002', 'P024_S002_001', 'P025_S001_001', 'P025_S001_002', 'P025_S002_001', 'P025_S002_002', 'P026_S002_001', 'P026_S002_002', 'P027_S001_001', 'P027_S002_002', 'P028_S002_001', 'P028_S002_002'])\n",
      "\n",
      "Dictionary after removal of keys from x_dict: \n",
      " dict_keys(['P001_S001_001', 'P001_S001_002', 'P001_S002_001', 'P001_S002_002', 'P002_S002_001', 'P002_S002_002', 'P003_S001_001', 'P003_S001_002', 'P003_S002_001', 'P003_S002_002', 'P004_S002_001', 'P004_S002_002', 'P005_S001_001', 'P005_S001_002', 'P006_S001_001', 'P006_S001_002', 'P007_S001_001', 'P007_S001_002', 'P007_S002_001', 'P007_S002_002', 'P008_S001_001', 'P008_S002_001', 'P008_S002_002', 'P009_S001_002', 'P009_S002_001', 'P009_S002_002', 'P010_S001_002', 'P010_S002_001', 'P010_S002_002', 'P011_S001_001', 'P011_S001_002', 'P011_S002_001', 'P011_S002_002', 'P012_S001_002', 'P012_S002_001', 'P013_S002_001', 'P013_S002_002', 'P014_S001_001', 'P014_S001_002', 'P014_S002_001', 'P014_S002_002', 'P015_S001_001', 'P015_S001_002', 'P015_S002_001', 'P016_S001_001', 'P017_S001_002', 'P017_S002_001', 'P017_S002_002', 'P018_S001_001', 'P018_S001_002', 'P018_S002_002', 'P019_S001_001', 'P019_S001_002', 'P019_S002_001', 'P019_S002_002', 'P020_S002_001', 'P020_S002_002', 'P021_S001_002', 'P021_S002_001', 'P022_S001_001', 'P022_S001_002', 'P022_S002_001', 'P022_S002_002', 'P023_S001_001', 'P023_S001_002', 'P023_S002_001', 'P024_S001_001', 'P024_S001_002', 'P024_S002_001', 'P025_S001_001', 'P025_S001_002', 'P025_S002_001', 'P025_S002_002', 'P026_S002_001', 'P026_S002_002', 'P027_S001_001', 'P027_S002_002', 'P028_S002_001', 'P028_S002_002'])\n"
     ]
    }
   ],
   "source": [
    "x_dict, y_dict = multi_to_binary_classification(x_dict_, y_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Length of data after removing mildly stressed subjects: 79\n",
      " Lenght og labels after removing  mildly stressed subjects: 79\n"
     ]
    }
   ],
   "source": [
    "print(f\" Length of data after removing mildly stressed subjects: {len(x_dict_)}\")\n",
    "print(f\" Lenght og labels after removing  mildly stressed subjects: {len(y_dict_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict, test_data_dict, val_data_dict, train_labels_dict, test_labels_dict, val_labels_dict = split_dataset(x_dict, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data set: 47\n",
      "Length of validation data set: 16\n",
      "Length of test data set: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train data set: {len(train_data_dict)}\")\n",
    "print(f\"Length of validation data set: {len(val_data_dict)}\")\n",
    "print(f\"Length of test data set: {len(test_data_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data set: (47, 8, 75000)\n",
      "Shape of validation data set: (16, 8, 75000)\n",
      "Shape of test data set: (16, 8, 75000)\n"
     ]
    }
   ],
   "source": [
    "train_data_arr = dict_to_arr(train_data_dict)\n",
    "test_data_arr = dict_to_arr(test_data_dict)\n",
    "val_data_arr = dict_to_arr(val_data_dict)\n",
    "\n",
    "train_labels_arr = np.reshape(np.array(list(train_labels_dict.values())), (len(train_data_arr),1))\n",
    "test_labels_arr = np.reshape(np.array(list(test_labels_dict.values())), (len(test_data_arr),1))\n",
    "val_labels_arr = np.reshape(np.array(list(val_labels_dict.values())), (len(val_data_arr),1))\n",
    "\n",
    "train_labels_arr[train_labels_arr == 2] = 1\n",
    "test_labels_arr[test_labels_arr == 2] = 1\n",
    "val_labels_arr[val_labels_arr == 2] = 1\n",
    "\n",
    "\n",
    "print(f\"Shape of train data set: {train_data_arr.shape}\")\n",
    "print(f\"Shape of validation data set: {val_data_arr.shape}\")\n",
    "print(f\"Shape of test data set: {test_data_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 1)\n",
      "(16, 1)\n",
      "(16, 1)\n",
      "[[[ 176.56046496  169.17522672  166.83933005 ...   79.36128698\n",
      "     72.92369365   33.03329823]\n",
      "  [  -9.47181605  -51.50450932  -74.30761332 ...  125.77405162\n",
      "    108.96015111   91.80628994]\n",
      "  [  71.99018778   83.53544327   90.8250806  ...   67.15063024\n",
      "     67.64766085   51.00812771]\n",
      "  ...\n",
      "  [ -23.05105877  -28.38653445  -31.26597997 ...   26.1782049\n",
      "     21.95334358   18.6066447 ]\n",
      "  [ 100.19381617  145.17249135  172.40644564 ...  156.00522048\n",
      "    169.16462822  157.04637211]\n",
      "  [  41.28636842   47.35224746   50.88059462 ...   15.36932308\n",
      "     17.74105128    6.51935797]]\n",
      "\n",
      " [[  50.85728944 -129.81724304 -226.21582133 ...    8.46767461\n",
      "    -32.85172101  -22.21515713]\n",
      "  [  57.99478128  -56.7016248  -116.49922495 ...   14.89929669\n",
      "    -11.06252622  -10.50772015]\n",
      "  [  77.79924029  -73.93169873 -154.00387943 ...   21.66554254\n",
      "    -22.40686419  -20.33516396]\n",
      "  ...\n",
      "  [  10.3592385   -16.03318607  -31.12930067 ...    5.17298471\n",
      "     -2.9929904    -4.15058907]\n",
      "  [ 172.29831975  -72.64347009 -199.99141765 ...   29.33841683\n",
      "    -34.85144776  -34.67136124]\n",
      "  [  46.08227582  -35.4288289   -75.41091426 ...    6.03828833\n",
      "    -12.82434399  -11.1770313 ]]\n",
      "\n",
      " [[  -0.86101412  -15.020936    -22.51221664 ...    6.13165003\n",
      "      5.03716845    3.95115333]\n",
      "  [  -6.70566223  -26.35406611  -34.98147983 ...    0.82311742\n",
      "     -2.33951286   -5.03488957]\n",
      "  [  -9.83332092  -17.41328448  -21.65347981 ...    1.75668509\n",
      "      1.89068853    3.36708401]\n",
      "  ...\n",
      "  [   3.6094827     0.8859153    -0.9717256  ...    7.37941646\n",
      "      7.01162053    5.88389822]\n",
      "  [  -6.04730166  -10.89706922  -13.01223886 ...  -11.63288453\n",
      "     -9.56359321   -5.8995794 ]\n",
      "  [ -19.56145235   -4.43380805    3.93294225 ...   -0.48315131\n",
      "      0.25289194    3.30550445]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  -1.87640561    9.67956255   13.19674243 ...  -21.09589484\n",
      "    -22.58760987  -22.0479216 ]\n",
      "  [   9.81780371   27.87070661   36.18761713 ...  -48.18759569\n",
      "    -49.00274951  -46.98323656]\n",
      "  [ -10.09811241  -21.14495337  -31.73637903 ...    5.04481324\n",
      "      2.07237442   -1.68992477]\n",
      "  ...\n",
      "  [  -8.37139216  -15.67660717  -23.80113072 ...   10.50079396\n",
      "      7.94976466    4.9041866 ]\n",
      "  [  -2.62322323  -25.43668658  -41.92013998 ...    8.02371892\n",
      "      5.94269599    0.42021851]\n",
      "  [   6.58100953   18.49130863   24.35147494 ...   -6.77774001\n",
      "     -8.39666811   -6.91306133]]\n",
      "\n",
      " [[   0.32638412   35.57508618   51.80907531 ...    7.43959861\n",
      "      3.5414616    -3.37144113]\n",
      "  [   3.39597141  -43.39933211  -72.56481784 ...  -15.5354274\n",
      "    -12.98113157   -4.41211145]\n",
      "  [ -32.57707457  121.46830513  202.01968651 ...   35.06909125\n",
      "     23.59085414  -13.83938985]\n",
      "  ...\n",
      "  [ -26.6079237   -11.43377183   -3.8553909  ...    2.69395023\n",
      "      4.15391744   -0.80762342]\n",
      "  [   5.18487904   17.21423826   23.59521802 ...    7.40698119\n",
      "      4.23159326    0.41401623]\n",
      "  [  -9.66334068  -26.95298355  -37.68720706 ...   28.85796468\n",
      "     29.86403505   31.02188832]]\n",
      "\n",
      " [[  18.50507446  -10.94961677  -26.44526483 ...   65.86783874\n",
      "     67.81522819   64.38559683]\n",
      "  [ -22.99182189   -4.21613512    4.60027395 ...  147.35318316\n",
      "    130.03034177  117.95077274]\n",
      "  [ 122.64050121   15.4026532   -38.7429688  ...   -1.76277949\n",
      "     27.599052     38.51287595]\n",
      "  ...\n",
      "  [  26.34214747   18.21191962   14.98773658 ...   -2.15704584\n",
      "      0.98392168    5.72291572]\n",
      "  [   2.53295734  -10.77102062  -18.34878165 ...   15.64961149\n",
      "     16.47539149   15.8504104 ]\n",
      "  [  -1.70038944    2.86706602    6.11892481 ...   48.08856297\n",
      "     44.71345308   43.2117874 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels_arr.shape)\n",
    "print(val_labels_arr.shape)\n",
    "print(test_labels_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.8016 - accuracy: 0.5532 - val_loss: nan - val_accuracy: 0.4375 - 11s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "3/3 - 9s - loss: 0.2035 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 9s/epoch - 3s/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "3/3 - 9s - loss: 0.0973 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 9s/epoch - 3s/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss did not improve from inf\n",
      "3/3 - 9s - loss: 0.0625 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 9s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss did not improve from inf\n",
      "3/3 - 9s - loss: 0.0511 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 9s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0347 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 11s/epoch - 4s/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss did not improve from inf\n",
      "3/3 - 10s - loss: 0.0271 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 10s/epoch - 3s/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0223 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 11s/epoch - 4s/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0224 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.5625 - 11s/epoch - 4s/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0195 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 11s/epoch - 4s/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0165 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 11s/epoch - 4s/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from inf\n",
      "3/3 - 10s - loss: 0.0164 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 10s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from inf\n",
      "3/3 - 11s - loss: 0.0114 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 11s/epoch - 4s/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from inf\n",
      "3/3 - 12s - loss: 0.0122 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 12s/epoch - 4s/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from inf\n",
      "3/3 - 12s - loss: 0.0116 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 12s/epoch - 4s/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from inf\n",
      "3/3 - 12s - loss: 0.0103 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 12s/epoch - 4s/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from inf\n",
      "3/3 - 25s - loss: 0.0090 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 25s/epoch - 8s/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from inf\n",
      "3/3 - 19s - loss: 0.0085 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 19s/epoch - 6s/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from inf\n",
      "3/3 - 14s - loss: 0.0085 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 14s/epoch - 5s/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0071 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0071 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from inf\n",
      "3/3 - 12s - loss: 0.0082 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 12s/epoch - 4s/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0069 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from inf\n",
      "3/3 - 14s - loss: 0.0061 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 14s/epoch - 5s/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from inf\n",
      "3/3 - 12s - loss: 0.0060 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 12s/epoch - 4s/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0070 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from inf\n",
      "3/3 - 15s - loss: 0.0062 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 15s/epoch - 5s/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0062 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0054 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.7500 - 13s/epoch - 4s/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from inf\n",
      "3/3 - 13s - loss: 0.0044 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6875 - 13s/epoch - 4s/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from inf\n",
      "3/3 - 17s - loss: 0.0048 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 17s/epoch - 6s/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from inf\n",
      "3/3 - 22s - loss: 0.0055 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 22s/epoch - 7s/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from inf\n",
      "3/3 - 15s - loss: 0.0059 - accuracy: 1.0000 - val_loss: nan - val_accuracy: 0.6250 - 15s/epoch - 5s/step\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8304\\143759807.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEEGNet_classification_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\annej\\OneDrive\\Documents\\GitHub\\MASTER-eeg-stress-det\\classifiers.py\u001b[0m in \u001b[0;36mEEGNet_classification_2\u001b[1;34m(train_data, test_data, val_data, train_labels, test_labels, val_labels)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;31m# Riemannian geometry classification (below)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     fittedModel = model.fit(train_data, train_labels, batch_size = 16, epochs = 100, \n\u001b[0m\u001b[0;32m    332\u001b[0m                             \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                             callbacks=[checkpointer], class_weight = class_weights)\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\annej\\anaconda3\\envs\\MNE\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probs = EEGNet_classification_2(train_data_arr, test_data_arr, val_data_arr, train_labels_arr, test_labels_arr, val_labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = probs.argmax(axis = -1)  \n",
    "print(preds)\n",
    "\n",
    "print(test_labels_arr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(preds, test_labels_arr, ['Stressed', 'Non-stressed'], title = 'EEGNet-8,2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
