{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classification of spoken digit recordings\n",
    "=========================================\n",
    "In this example we use the 1D scattering transform to represent spoken digits,\n",
    "which we then classify using a simple classifier. This shows that 1D scattering\n",
    "representations are useful for this type of problem.\n",
    "This dataset is automatically downloaded using the DeepLake dataloader.\n",
    "Downloading and precomputing scattering coefficients should take about 5 min.\n",
    "Running the gradient descent takes about 1 min.\n",
    "Results:\n",
    "Training accuracy = 99.7%\n",
    "Testing accuracy = 98.0%\n",
    "\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "# Preliminaries\n",
    "# -------------\n",
    "#\n",
    "# Since we're using TensorFlow and Keras to train the model, import the\n",
    "# relevant modules.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "###############################################################################\n",
    "# To handle audio file I/O, we import `os` and `scipy.io.wavfile`. We also need\n",
    "# `numpy` for some basic array manipulation.\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "###############################################################################\n",
    "# To download the dataset, we use the `datalake` package.\n",
    "import deeplake\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we import the `Scattering1D` class from the `kymatio.keras`\n",
    "# package. The `Scattering1D` class is what lets us calculate the scattering\n",
    "# transform.\n",
    "\n",
    "from kymatio.keras import Scattering1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Pipeline setup\n",
    "# --------------\n",
    "# We start by specifying the dimensions of our processing pipeline along with\n",
    "# some other parameters.\n",
    "#\n",
    "# First, we have signal length. Longer signals are truncated and shorter\n",
    "# signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n",
    "# little over a second.\n",
    "\n",
    "T = 2 ** 13\n",
    "\n",
    "###############################################################################\n",
    "# Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n",
    "# and the number of wavelets per octave.\n",
    "J = 8\n",
    "Q = 12\n",
    "\n",
    "###############################################################################\n",
    "# We need a small constant to add to the scattering coefficients before\n",
    "# computing the logarithm. This prevents very large values when the scattering\n",
    "# coefficients are very close to zero.\n",
    "log_eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Loading the data\n",
    "# ----------------\n",
    "# Once the parameter are set, we can start loading the data into a format that\n",
    "# can be fed into the scattering transform and then a logistic regression\n",
    "# classifier.\n",
    "#\n",
    "# We first download the dataset.\n",
    "\n",
    "ds = deeplake.load(\"hub://activeloop/spoken_mnist\", verbose=False)\n",
    "ds = ds[:200]\n",
    "\n",
    "###############################################################################\n",
    "# Set up NumPy arrays to hold the audio signals (`x_all`), the labels\n",
    "# (`y_all`), and whether the signal is in the train or test set (`subset`).\n",
    "\n",
    "x_all = np.zeros((len(ds), T), dtype=\"float32\")\n",
    "y_all = np.zeros(len(ds), dtype=\"uint8\")\n",
    "subset = np.zeros(len(ds), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# For each file in the dataset, we extract its label `y`. Each speaker repeats\n",
    "# every digit 50 times in total, so we take the first 5 of these for the test\n",
    "# set. The actual signals are normalized to have maximum amplitude one, and are\n",
    "# truncated or zero-padded to the desired length `T`. They are then stored in\n",
    "# the `x_all` array while their labels are in `y_all`.\n",
    "\n",
    "for k, sample in enumerate(ds):\n",
    "    y = sample[\"labels\"].numpy()[0]\n",
    "\n",
    "    # Each speakerâ€“digit combination is repeated 50 times so select the\n",
    "    # first 5 recordings of each set to put in test set.\n",
    "    if (k % 50) < 5:\n",
    "        subset[k] = 1\n",
    "    else:\n",
    "        subset[k] = 0\n",
    "\n",
    "    # Load the audio signal and normalize it.\n",
    "    x = sample[\"audio\"].numpy()[:, 0]\n",
    "    x = x.astype(\"float32\")\n",
    "    x /= np.max(np.abs(x))\n",
    "\n",
    "    # If it's too long, truncate it.\n",
    "    if len(x) > T:\n",
    "        x = x[:T]\n",
    "\n",
    "    # If it's too short, zero-pad it.\n",
    "    start = (T - len(x)) // 2\n",
    "\n",
    "    x_all[k, start:start + len(x)] = x\n",
    "    y_all[k] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Log-scattering layer\n",
    "# --------------------\n",
    "# We now create a classification model using the `Scattering1D` Keras layer.\n",
    "# First, we take the input signals of length `T`.\n",
    "\n",
    "x_in = layers.Input(shape=(T))\n",
    "\n",
    "###############################################################################\n",
    "# These are fed into the `Scattering1D` layer.\n",
    "\n",
    "x = Scattering1D(J, Q=Q)(x_in)\n",
    "\n",
    "###############################################################################\n",
    "# Since it does not carry useful information, we remove the zeroth-order\n",
    "# scattering coefficients, which are always placed in the first channel of\n",
    "# the scattering transform.\n",
    "\n",
    "x = layers.Lambda(lambda x: x[..., 1:, :])(x)\n",
    "\n",
    "# To increase discriminability, we take the logarithm of the scattering\n",
    "# coefficients (after adding a small constant to make sure nothing blows up\n",
    "# when scattering coefficients are close to zero). This is known as the\n",
    "# log-scattering transform.\n",
    "\n",
    "x = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)\n",
    "\n",
    "###############################################################################\n",
    "# We then average along the last dimension (time) to get a time-shift\n",
    "# invariant representation.\n",
    "\n",
    "x = layers.GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we apply batch normalization to ensure that the data is within a\n",
    "# moderate range.\n",
    "\n",
    "x = layers.BatchNormalization(axis=1)(x)\n",
    "\n",
    "###############################################################################\n",
    "# These features are then used to classify the input signal using a dense\n",
    "# layer followed by a softmax activation.\n",
    "\n",
    "x_out = layers.Dense(10, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8192)]            0         \n",
      "                                                                 \n",
      " scattering1d (Scattering1D)  (None, 337, 32)          0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 336, 32)           0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 336, 32)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 336)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 336)              1344      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                3370      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,714\n",
      "Trainable params: 4,042\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 64s 12s/step - loss: 3.0021 - accuracy: 0.1736 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 9s 2s/step - loss: 2.6655 - accuracy: 0.2014 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 9s 2s/step - loss: 2.4360 - accuracy: 0.2292 - val_loss: 2.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 8s 3s/step - loss: 2.3016 - accuracy: 0.2083 - val_loss: 6.6782 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 8s 3s/step - loss: 2.2131 - accuracy: 0.1944 - val_loss: 10.5917 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 7s 3s/step - loss: 2.1384 - accuracy: 0.2431 - val_loss: 13.2836 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 2.0552 - accuracy: 0.3194 - val_loss: 14.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 9s 4s/step - loss: 1.9632 - accuracy: 0.3681 - val_loss: 13.6135 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.8710 - accuracy: 0.4653 - val_loss: 10.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.7811 - accuracy: 0.5486 - val_loss: 7.7911 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 8s 2s/step - loss: 1.6874 - accuracy: 0.6667 - val_loss: 4.9441 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 8s 2s/step - loss: 1.6010 - accuracy: 0.7292 - val_loss: 2.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.5091 - accuracy: 0.7639 - val_loss: 1.2360 - val_accuracy: 0.1944\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 8s 2s/step - loss: 1.4166 - accuracy: 0.8333 - val_loss: 0.8909 - val_accuracy: 0.6389\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.3242 - accuracy: 0.8889 - val_loss: 1.1059 - val_accuracy: 0.2222\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.2277 - accuracy: 0.9375 - val_loss: 1.6184 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.1318 - accuracy: 0.9722 - val_loss: 1.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.0344 - accuracy: 0.9861 - val_loss: 1.0509 - val_accuracy: 0.1111\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9396 - accuracy: 0.9931 - val_loss: 0.4351 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.8474 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.7597 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.6731 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.5975 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.5232 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4584 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3997 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3036 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2643 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2331 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1781 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1591 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1283 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0200 - accuracy: 1.0000 - 373ms/epoch - 373ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020042993128299713, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Finally, we create the model and display it.\n",
    "\n",
    "model = tf.keras.models.Model(x_in, x_out)\n",
    "model.summary()\n",
    "\n",
    "###############################################################################\n",
    "# Training the classifier\n",
    "# -----------------------\n",
    "# Having set up the model, we attach an Adam optimizer and a cross-entropy\n",
    "# loss function.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "###############################################################################\n",
    "# We then train the model using `model.fit`. The training data is given by\n",
    "# those indices satisfying `subset == 0`.\n",
    "\n",
    "model.fit(x_all[subset == 0], y_all[subset == 0], epochs=50,\n",
    "          batch_size=64, validation_split=0.2)\n",
    "\n",
    "###############################################################################\n",
    "# Finally, we evaluate the model on the held-out test data. These are given by\n",
    "# the indices `subset == 1`.\n",
    "\n",
    "model.evaluate(x_all[subset == 1], y_all[subset == 1], verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER_MNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
