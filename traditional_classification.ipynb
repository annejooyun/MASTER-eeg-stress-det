{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data import extract_eeg_data, segment_data\n",
    "from load_data import load_kfold_data\n",
    "from utils.labels import get_pss_labels, get_stai_labels\n",
    "from utils.valid_recs import get_valid_recs\n",
    "#from features import all_features, hjorth_features, differential_entropy, kymatio_wave_scattering\n",
    "from classifiers import knn_classification, svm_classification\n",
    "\n",
    "import utils.variables as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Generating all recordings ----\n",
      "All records generated\n",
      "\n",
      "---- Filtering out invalid recordings ----\n",
      "ERROR 1) Failed to read data for recording P006_S002_001\n",
      "ERROR 1) Failed to read data for recording P006_S002_002\n",
      "ERROR 1) Failed to read data for recording P028_S002_001\n",
      "ERROR 1) Failed to read data for recording P028_S002_002\n",
      "\n",
      "---- Returning valid recordings ----\n",
      "['P001_S001_001', 'P001_S001_002', 'P001_S002_001', 'P001_S002_002', 'P002_S001_001', 'P002_S001_002', 'P002_S002_001', 'P002_S002_002', 'P003_S001_001', 'P003_S001_002', 'P003_S002_001', 'P003_S002_002', 'P004_S001_001', 'P004_S001_002', 'P004_S002_001', 'P004_S002_002', 'P005_S001_001', 'P005_S001_002', 'P005_S002_001', 'P005_S002_002', 'P006_S001_001', 'P006_S001_002', 'P007_S001_001', 'P007_S001_002', 'P007_S002_001', 'P007_S002_002', 'P008_S001_001', 'P008_S001_002', 'P008_S002_001', 'P008_S002_002', 'P009_S001_001', 'P009_S001_002', 'P009_S002_001', 'P009_S002_002', 'P010_S001_002', 'P010_S002_001', 'P010_S002_002', 'P011_S001_001', 'P011_S001_002', 'P011_S002_001', 'P011_S002_002', 'P012_S001_001', 'P012_S001_002', 'P012_S002_001', 'P012_S002_002', 'P013_S002_001', 'P013_S002_002', 'P014_S001_001', 'P014_S001_002', 'P014_S002_001', 'P014_S002_002', 'P015_S001_001', 'P015_S001_002', 'P015_S002_001', 'P015_S002_002', 'P016_S001_001', 'P016_S001_002', 'P016_S002_001', 'P016_S002_002', 'P017_S001_001', 'P017_S001_002', 'P017_S002_001', 'P017_S002_002', 'P018_S001_001', 'P018_S001_002', 'P018_S002_001', 'P018_S002_002', 'P019_S001_001', 'P019_S001_002', 'P019_S002_001', 'P019_S002_002', 'P020_S001_002', 'P020_S002_001', 'P020_S002_002', 'P021_S001_001', 'P021_S001_002', 'P021_S002_001', 'P021_S002_002', 'P022_S001_001', 'P022_S001_002', 'P022_S002_001', 'P022_S002_002', 'P023_S001_001', 'P023_S001_002', 'P023_S002_001', 'P024_S001_001', 'P024_S001_002', 'P024_S002_001', 'P024_S002_002', 'P025_S001_001', 'P025_S001_002', 'P025_S002_001', 'P025_S002_002', 'P026_S001_001', 'P026_S001_002', 'P026_S002_001', 'P026_S002_002', 'P027_S001_001', 'P027_S001_002', 'P027_S002_001', 'P027_S002_002', 'P028_S001_001', 'P028_S001_002']\n",
      "\n",
      "Length of data: 103\n",
      "P006_S002_001 has invalid record length\n",
      "P006_S002_002 has invalid record length\n",
      "P010_S001_001 has invalid record length\n",
      "P013_S001_001 has invalid record length\n",
      "P013_S001_002 has invalid record length\n",
      "P020_S001_001 has invalid record length\n",
      "P023_S002_002 has invalid record length\n",
      "P028_S002_001 has invalid record length\n",
      "P028_S002_002 has invalid record length\n",
      "\n",
      "---- Labels ----\n",
      "{'P001_S001_001': 0, 'P001_S001_002': 0, 'P001_S002_001': 0, 'P001_S002_002': 0, 'P002_S001_001': 1, 'P002_S001_002': 1, 'P002_S002_001': 0, 'P002_S002_002': 0, 'P003_S001_001': 2, 'P003_S001_002': 2, 'P003_S002_001': 0, 'P003_S002_002': 0, 'P004_S001_001': 1, 'P004_S001_002': 1, 'P004_S002_001': 0, 'P004_S002_002': 0, 'P005_S001_001': 0, 'P005_S001_002': 0, 'P005_S002_001': 1, 'P005_S002_002': 1, 'P006_S001_001': 2, 'P006_S001_002': 2, 'P007_S001_001': 2, 'P007_S001_002': 2, 'P007_S002_001': 0, 'P007_S002_002': 0, 'P008_S001_001': 2, 'P008_S001_002': 1, 'P008_S002_001': 0, 'P008_S002_002': 0, 'P009_S001_001': 1, 'P009_S001_002': 2, 'P009_S002_001': 0, 'P009_S002_002': 0, 'P010_S001_002': 0, 'P010_S002_001': 0, 'P010_S002_002': 0, 'P011_S001_001': 2, 'P011_S001_002': 2, 'P011_S002_001': 0, 'P011_S002_002': 2, 'P012_S001_001': 1, 'P012_S001_002': 2, 'P012_S002_001': 2, 'P012_S002_002': 1, 'P013_S002_001': 0, 'P013_S002_002': 0, 'P014_S001_001': 2, 'P014_S001_002': 0, 'P014_S002_001': 0, 'P014_S002_002': 0, 'P015_S001_001': 2, 'P015_S001_002': 2, 'P015_S002_001': 0, 'P015_S002_002': 1, 'P016_S001_001': 0, 'P016_S001_002': 1, 'P016_S002_001': 1, 'P016_S002_002': 1, 'P017_S001_001': 1, 'P017_S001_002': 0, 'P017_S002_001': 0, 'P017_S002_002': 0, 'P018_S001_001': 2, 'P018_S001_002': 2, 'P018_S002_001': 1, 'P018_S002_002': 2, 'P019_S001_001': 2, 'P019_S001_002': 2, 'P019_S002_001': 0, 'P019_S002_002': 0, 'P020_S001_002': 1, 'P020_S002_001': 0, 'P020_S002_002': 0, 'P021_S001_001': 1, 'P021_S001_002': 2, 'P021_S002_001': 0, 'P021_S002_002': 1, 'P022_S001_001': 2, 'P022_S001_002': 2, 'P022_S002_001': 0, 'P022_S002_002': 0, 'P023_S001_001': 2, 'P023_S001_002': 2, 'P023_S002_001': 0, 'P024_S001_001': 2, 'P024_S001_002': 2, 'P024_S002_001': 0, 'P024_S002_002': 1, 'P025_S001_001': 2, 'P025_S001_002': 2, 'P025_S002_001': 0, 'P025_S002_002': 2, 'P026_S001_001': 1, 'P026_S001_002': 1, 'P026_S002_001': 0, 'P026_S002_002': 0, 'P027_S001_001': 2, 'P027_S001_002': 1, 'P027_S002_001': 1, 'P027_S002_002': 0, 'P028_S001_001': 0, 'P028_S001_002': 0}\n",
      "\n",
      "Length of data after removing invalid labels: 103\n",
      "Length of labels after removing invalid labels: 103\n",
      "\n",
      "The extracted keys : \n",
      "['P002_S001_001', 'P002_S001_002', 'P004_S001_001', 'P004_S001_002', 'P005_S002_001', 'P005_S002_002', 'P008_S001_002', 'P009_S001_001', 'P012_S001_001', 'P012_S002_002', 'P015_S002_002', 'P016_S001_002', 'P016_S002_001', 'P016_S002_002', 'P017_S001_001', 'P018_S002_001', 'P020_S001_002', 'P021_S001_001', 'P021_S002_002', 'P024_S002_002', 'P026_S001_001', 'P026_S001_002', 'P027_S001_002', 'P027_S002_001']\n",
      "\n",
      "Length of data after removing mildly stressed subjects: 79\n",
      "Length of labels after removing  mildly stressed subjects: 79\n",
      "\n",
      "Shape of train data set: (60, 8, 75000)\n",
      "Shape of train labels set: (60, 1)\n",
      "Shape of test data set: (19, 8, 75000)\n",
      "Shape of test labels set: (19, 1)\n"
     ]
    }
   ],
   "source": [
    "data_type = 'raw'\n",
    "label_type = 'stai'\n",
    "\n",
    "#train_data, test_data, val_data, train_labels, test_labels, val_labels = load_data(data_type, label_type, epoched = True, binary = True)\n",
    "train_data, test_data, train_labels, test_labels = load_kfold_data(data_type, label_type, epoched = False, binary = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 8, 75000)\n",
      "(60, 1)\n",
      "(480, 75000)\n",
      "(480,)\n",
      "(152, 75000)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "#Reshape data\n",
    "train_data = np.reshape(train_data, (train_data.shape[0]*train_data.shape[1], train_data.shape[2]))\n",
    "train_labels = np.repeat(train_labels, repeats = 8, axis = 1).reshape(-1,1)\n",
    "train_labels = train_labels.ravel()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0]*test_data.shape[1],test_data.shape[2]))\n",
    "test_labels = np.repeat(test_labels, repeats = 8, axis = 1).reshape(-1,1)\n",
    "test_labels = test_labels.ravel()\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, x_test, y, test_labels = train_test_split(x_epochs, y_epochs, test_size=0.2, random_state=1)\n",
    "#x_train, x_val, train_labels, val_labels = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "# freq_bands = np.array([1, 4, 8, 12, 30, 50])\n",
    "# features = freq_band_features(dataset, freq_bands)\n",
    "# features = hjorth_features(dataset)\n",
    "# features = entropy_features(dataset)\n",
    "# features = fractal_features(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data with stai labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 9000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/neighbors/_classification.py\", line 213, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'leaf_size' parameter of KNeighborsClassifier must be an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/AnneJoo/.local/share/virtualenvs/MASTER-eeg-stress-det-zSpBlwVN/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375\n",
      " 0.66875    0.67708333 0.65208333 0.65416667 0.69375    0.69791667\n",
      " 0.66041667 0.66041667 0.72083333 0.71875    0.70208333 0.70208333\n",
      " 0.725      0.72708333 0.70208333 0.70833333 0.7375     0.7375    ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Classification accuracy: 0.822368 \n",
      "\n",
      " Confusion matrix:\n",
      "[[78 10]\n",
      " [17 47]]\n",
      "Accuracy, Sensitivity, Specificyty:\n",
      "\n",
      "[82.24 82.11 82.46]\n"
     ]
    }
   ],
   "source": [
    "print(f'{data_type} data with {label_type} labels')\n",
    "knn_classification(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data with stai labels\n",
      "\n",
      "Results:\n",
      "Classification accuracy: 0.875000 \n",
      "\n",
      " Confusion matrix:\n",
      "[[81  7]\n",
      " [12 52]]\n",
      "Accuracy, Sensitivity, Specificyty:\n",
      "\n",
      "[87.5  87.1  88.14]\n"
     ]
    }
   ],
   "source": [
    "print(f'{data_type} data with {label_type} labels')\n",
    "svm_classification(train_data, test_data, train_labels, test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6df28382c6e70c1c1d3c02fa7b17b6f3b6fcf9f5d22d2410beebd122bfaf45e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
